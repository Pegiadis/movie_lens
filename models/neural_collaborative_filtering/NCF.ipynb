{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-02T19:25:40.819573987Z",
     "start_time": "2023-08-02T19:25:39.966859239Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# ratings = pd.read_csv('../../data/lens_tmdb/ratings.csv')\n",
    "ratings = pd.read_csv('../../data/lens_tmdb/ratings_small.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T19:25:40.835621857Z",
     "start_time": "2023-08-02T19:25:40.808571956Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(100004, 4)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T19:25:40.845208915Z",
     "start_time": "2023-08-02T19:25:40.840071369Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Convert userId and movieId to categorical\n",
    "ratings['userId'] = ratings['userId'].astype('category')\n",
    "ratings['movieId'] = ratings['movieId'].astype('category')\n",
    "\n",
    "# Define the number of users and movies\n",
    "num_users = ratings['userId'].nunique()\n",
    "num_movies = ratings['movieId'].nunique()\n",
    "\n",
    "# Create a map for user & movie to categorical codes\n",
    "user_map = {i: user_code for i, user_code in enumerate(ratings['userId'].cat.categories)}\n",
    "movie_map = {i: movie_code for i, movie_code in enumerate(ratings['movieId'].cat.categories)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T19:25:40.861112376Z",
     "start_time": "2023-08-02T19:25:40.844097282Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Train test split\n",
    "train_ratings, test_ratings = train_test_split(ratings, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T19:25:40.862659458Z",
     "start_time": "2023-08-02T19:25:40.856790157Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=100, hidden_layers=[100], dropout=False):\n",
    "        super(NCF, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        input_size = 2 * emb_size\n",
    "\n",
    "        for hidden_layer_size in hidden_layers:\n",
    "            self.hidden_layers.append(nn.Linear(input_size, hidden_layer_size))\n",
    "            input_size = hidden_layer_size\n",
    "\n",
    "        self.output_layer = nn.Linear(input_size, 1)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embedding = self.user_emb(user_indices)\n",
    "        item_embedding = self.item_emb(item_indices)\n",
    "        x = torch.cat([user_embedding, item_embedding], dim=-1)  # concatenate user and item embeddings\n",
    "\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = hidden_layer(x)\n",
    "            x = torch.relu(x)\n",
    "            if self.dropout:\n",
    "                x = nn.Dropout()(x)\n",
    "\n",
    "        x = self.output_layer(x)\n",
    "        return 1 + 4*torch.sigmoid(x).view(-1)  # This scales the sigmoid output to the range [1, 5]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T19:29:39.575320870Z",
     "start_time": "2023-08-02T19:29:39.522494824Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = NCF(num_users=num_users, num_items=num_movies, emb_size=100, hidden_layers=[128, 64, 32], dropout=True)\n",
    "\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T19:29:40.094591182Z",
     "start_time": "2023-08-02T19:29:40.070110515Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.7110\n",
      "Epoch [2/100], Loss: 1.6497\n",
      "Epoch [3/100], Loss: 1.5940\n",
      "Epoch [4/100], Loss: 1.5433\n",
      "Epoch [5/100], Loss: 1.4977\n",
      "Epoch [6/100], Loss: 1.4577\n",
      "Epoch [7/100], Loss: 1.4147\n",
      "Epoch [8/100], Loss: 1.3782\n",
      "Epoch [9/100], Loss: 1.3408\n",
      "Epoch [10/100], Loss: 1.3075\n",
      "Epoch [11/100], Loss: 1.2783\n",
      "Epoch [12/100], Loss: 1.2481\n",
      "Epoch [13/100], Loss: 1.2258\n",
      "Epoch [14/100], Loss: 1.2109\n",
      "Epoch [15/100], Loss: 1.1996\n",
      "Epoch [16/100], Loss: 1.1901\n",
      "Epoch [17/100], Loss: 1.1879\n",
      "Epoch [18/100], Loss: 1.1850\n",
      "Epoch [19/100], Loss: 1.1894\n",
      "Epoch [20/100], Loss: 1.1859\n",
      "Epoch [21/100], Loss: 1.1833\n",
      "Epoch [22/100], Loss: 1.1755\n",
      "Epoch [23/100], Loss: 1.1643\n",
      "Epoch [24/100], Loss: 1.1583\n",
      "Epoch [25/100], Loss: 1.1445\n",
      "Epoch [26/100], Loss: 1.1372\n",
      "Epoch [27/100], Loss: 1.1308\n",
      "Epoch [28/100], Loss: 1.1208\n",
      "Epoch [29/100], Loss: 1.1161\n",
      "Epoch [30/100], Loss: 1.1078\n",
      "Epoch [31/100], Loss: 1.1065\n",
      "Epoch [32/100], Loss: 1.1046\n",
      "Epoch [33/100], Loss: 1.0992\n",
      "Epoch [34/100], Loss: 1.0965\n",
      "Epoch [35/100], Loss: 1.0949\n",
      "Epoch [36/100], Loss: 1.0881\n",
      "Epoch [37/100], Loss: 1.0861\n",
      "Epoch [38/100], Loss: 1.0811\n",
      "Epoch [39/100], Loss: 1.0737\n",
      "Epoch [40/100], Loss: 1.0686\n",
      "Epoch [41/100], Loss: 1.0625\n",
      "Epoch [42/100], Loss: 1.0621\n",
      "Epoch [43/100], Loss: 1.0529\n",
      "Epoch [44/100], Loss: 1.0549\n",
      "Epoch [45/100], Loss: 1.0455\n",
      "Epoch [46/100], Loss: 1.0435\n",
      "Epoch [47/100], Loss: 1.0434\n",
      "Epoch [48/100], Loss: 1.0364\n",
      "Epoch [49/100], Loss: 1.0323\n",
      "Epoch [50/100], Loss: 1.0294\n",
      "Epoch [51/100], Loss: 1.0256\n",
      "Epoch [52/100], Loss: 1.0228\n",
      "Epoch [53/100], Loss: 1.0172\n",
      "Epoch [54/100], Loss: 1.0133\n",
      "Epoch [55/100], Loss: 1.0139\n",
      "Epoch [56/100], Loss: 1.0052\n",
      "Epoch [57/100], Loss: 1.0037\n",
      "Epoch [58/100], Loss: 0.9997\n",
      "Epoch [59/100], Loss: 0.9957\n",
      "Epoch [60/100], Loss: 0.9963\n",
      "Epoch [61/100], Loss: 0.9922\n",
      "Epoch [62/100], Loss: 0.9870\n",
      "Epoch [63/100], Loss: 0.9848\n",
      "Epoch [64/100], Loss: 0.9775\n",
      "Epoch [65/100], Loss: 0.9792\n",
      "Epoch [66/100], Loss: 0.9783\n",
      "Epoch [67/100], Loss: 0.9704\n",
      "Epoch [68/100], Loss: 0.9699\n",
      "Epoch [69/100], Loss: 0.9680\n",
      "Epoch [70/100], Loss: 0.9612\n",
      "Epoch [71/100], Loss: 0.9606\n",
      "Epoch [72/100], Loss: 0.9599\n",
      "Epoch [73/100], Loss: 0.9531\n",
      "Epoch [74/100], Loss: 0.9526\n",
      "Epoch [75/100], Loss: 0.9519\n",
      "Epoch [76/100], Loss: 0.9458\n",
      "Epoch [77/100], Loss: 0.9432\n",
      "Epoch [78/100], Loss: 0.9441\n",
      "Epoch [79/100], Loss: 0.9366\n",
      "Epoch [80/100], Loss: 0.9357\n",
      "Epoch [81/100], Loss: 0.9349\n",
      "Epoch [82/100], Loss: 0.9319\n",
      "Epoch [83/100], Loss: 0.9311\n",
      "Epoch [84/100], Loss: 0.9274\n",
      "Epoch [85/100], Loss: 0.9260\n",
      "Epoch [86/100], Loss: 0.9222\n",
      "Epoch [87/100], Loss: 0.9204\n",
      "Epoch [88/100], Loss: 0.9169\n",
      "Epoch [89/100], Loss: 0.9150\n",
      "Epoch [90/100], Loss: 0.9134\n",
      "Epoch [91/100], Loss: 0.9124\n",
      "Epoch [92/100], Loss: 0.9082\n",
      "Epoch [93/100], Loss: 0.9052\n",
      "Epoch [94/100], Loss: 0.9015\n",
      "Epoch [95/100], Loss: 0.9051\n",
      "Epoch [96/100], Loss: 0.9015\n",
      "Epoch [97/100], Loss: 0.9002\n",
      "Epoch [98/100], Loss: 0.8930\n",
      "Epoch [99/100], Loss: 0.8914\n",
      "Epoch [100/100], Loss: 0.8902\n"
     ]
    }
   ],
   "source": [
    "# Convert training data to tensors\n",
    "train_user_tensor = torch.from_numpy(train_ratings['userId'].cat.codes.values).long()\n",
    "train_movie_tensor = torch.from_numpy(train_ratings['movieId'].cat.codes.values).long()\n",
    "train_rating_tensor = torch.from_numpy(train_ratings['rating'].values).float()\n",
    "\n",
    "from tqdm import tqdm\n",
    "# Training loop\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    prediction = model(train_user_tensor, train_movie_tensor)\n",
    "    loss = criterion(prediction, train_rating_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, loss.item()))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T19:29:58.451917402Z",
     "start_time": "2023-08-02T19:29:40.710779146Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.9425989985466003\n",
      "Test MAE: 0.7255163788795471\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Convert test data to tensors\n",
    "test_user_tensor = torch.from_numpy(test_ratings['userId'].cat.codes.values).long()\n",
    "test_movie_tensor = torch.from_numpy(test_ratings['movieId'].cat.codes.values).long()\n",
    "test_rating_tensor = torch.from_numpy(test_ratings['rating'].values).float()\n",
    "\n",
    "# Get model's predictions on the test set\n",
    "model.eval()  # Switch to evaluation mode\n",
    "with torch.no_grad():\n",
    "    predictions = model(test_user_tensor, test_movie_tensor)\n",
    "\n",
    "# Convert predictions to a numpy array\n",
    "predictions_np = predictions.numpy()\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(test_rating_tensor, predictions_np))\n",
    "print(f'Test RMSE: {rmse}')\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(test_rating_tensor, predictions_np)\n",
    "print(f'Test MAE: {mae}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T19:35:21.370442951Z",
     "start_time": "2023-08-02T19:35:21.323122184Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
